---
title: "Network Analysis Functions"
output: html_document
---

These are the main functions used to create and analyze our network.

First, install and load the following packages:

```{r, results='hide'}
library(igraph)
library(sna)
library(intergraph)
library(RColorBrewer)
library(randomcoloR)
library(dplyr)
library(ggplot2)
library(caret) 
library(ggplot2) 
library(reshape2) 
```

**Load Functions**

The following function builds the graph with all of the node and edge level attributes that are found in the data provided or derived by the data provided.

```{r}
build_graph <- function (nodes, edges) {
  g = graph.empty(nrow(nodes), directed = FALSE)
  # covert R factor to character
  V(g)$name = as.character(nodes$Id)
  V(g)$ACTIVITY = as.character(nodes$ACTIVITY)  #### Used for Q2
  V(g)$pi_key = as.character(nodes$pi_key)
  V(g)$discipline_classification = as.character(nodes$discipline_classification) #### Used for Q4
  # a edge array: odd index -> source, even index -> target
  edge_list = as.vector(t(cbind(as.character(edges$Source), as.character(edges$Target))))
  g = add_edges(g, edge_list)
  E(g)$Label = as.character(edges$Label)
  E(g)$PUB_YEAR = as.character(edges$PUB_YEAR)
  E(g)$COUNTRY = as.character(edges$COUNTRY)
  E(g)$ACTIVITY = as.character(edges$ACTIVITY)
  E(g)$PMID = as.character(edges$PMID_x)
  #E(g)$weight = edges$normalized_discipline_weight ### Used for weighted degree Q4
  E(g)$weight = edges$normalized_activity_weight ### Used for weighted degree Q3
  E(g)$discipline = as.character(edges$discipline_classification)
  V(g)$Group = as.character(nodes$Group) #### Used for Q1
  
  V(g)$Unique_activities = as.character(nodes$unique_activities)
  V(g)$Project_count = as.character(nodes$project_count)
  V(g)$Act_per_proj_quant = as.character(nodes$Act_per_proj_quant) ### Used for Q3
  V(g)$Activity_per_project = as.character(nodes$activity_per_project)
  V(g)$discipline.group = as.character(nodes$discipline.group)
  V(g)$unique_activities = as.character(nodes$unique_activities)
  V(g)$unique_activity_grouped = as.character(nodes$unique_activity_grouped)
  
  #remove nodes by degree 
  #g = filter_node_by_number_publication(g, num_pub_floor)
  return(g)
}
```

**The next functions are essential for calculating the network level statistics.**

This function calculates assortativity, which is a single statistic measuring the degree of connections betweeen similiar nodes.
```{r}
get_assortativity <- function(g, attr) {
  cat = igraph::get.vertex.attribute(g, attr )
  #!! have to convert vertex values from chartacter to factor
  assortativity = assortativity_nominal(g, as.factor(cat), directed = F)
  return(assortativity);
}
```
The next function is used to calculate average degree, which calculates the average connections per node for each attribute specified.
```{r}
get_degree <- function(g, attr){
  cat = igraph::get.vertex.attribute(g, attr )
  V(g)$degree = igraph::degree(g)
  V(g)$strength = igraph::strength(g)
  return(g)
}
```
The next function calculates a confusion matrix which generates percentages associated with frequencies of collaboration across levels of a particular attribute.
```{r}
# calcuate a confusion table between groups 
get_group_confusion <- function(nodes, edges, attr) {
  from_to = select(edges, Source, Target)
  from_to$Source = as.character(from_to$Source)
  from_to$Target = as.character(from_to$Target)
  nodes$Id = as.character(nodes$Id)
  from_to = left_join(from_to, nodes, by= c('Source' = 'Id'))
  from_to = left_join(from_to, nodes, by= c('Target' = 'Id'))
  x = paste0(attr, '.x')
  y = paste0(attr, '.y')
  cols <- c(x, y)
  colNums <- match(cols,colnames(from_to))
  fg_tg = select_(from_to, x, y)
  colnames(fg_tg) = c('node_a', 'node_b')
  Source_Groups = as.factor(fg_tg$node_a);
  Target_Groups = as.factor(fg_tg$node_b);
  tbl = table(Source_Groups, Target_Groups)
  prop_table = prop.table(tbl)
  #since it is undirected graph, convert it into triangular
  p1 = prop_table;
  p2 = t(prop_table);
  p3 = p1 + p2
  p4 = lower.tri.remove(p3)
  diag(p4) = diag(p4) / 2
  prop_table = p4
  return(prop_table)
}
```
The next function calculates the transitivity, which measures how tightly knit a community is.
```{r}
get_transitivity <- function(g) {
  cc = transitivity(g, type='local', vids=V(g)$name)
  V(g)$cc = cc 
  return(g)
}
```
The following function counts the number of cliques with *n* connected nodes in the network. For our analysis, we used this function to count complete triads.
```{r}
# looping through clique to count group membership in clique 
get_cliques_membership <- function(g, n, attr) {
  cs  = cliques(g, min=n)
  cs_len = sapply(cs, length)
  cs_n = cs[cs_len == n]
  cat = unique(igraph::get.vertex.attribute(g, attr))
  numCli = length(cs_n)
  m = matrix(0, nrow = numCli, ncol = length(cat))
  colnames(m) = cat
  #looping throught cliques to count membership by groups
  for (i in 1:numCli) {
    c = cs_n[[i]]
    a = vertex_attr(g,attr, c)
    for (ct in cat) {
      m[i,ct] = sum(a==ct)
    }
  }
  return(m)
}
```
This function takes the confusion matrix and adjusts the percentages to reflect the percentages to be a proportion of the particular level of an attribute rather than reflecting the overall distribution.
```{r}
get_confusion_within_group <- function(prop_table) {
  conf_mtx <- prop_table
  conf_mtx[lower.tri(conf_mtx)]<-t(conf_mtx)[lower.tri(conf_mtx)]
  conf_mtx <- data.frame(conf_mtx) %>% dplyr::mutate(Source_Groups = as.character(Source_Groups), 
                                                     Target_Groups = as.character(Target_Groups))
  lvl <- unique(conf_mtx$Source_Groups)
  conf_mtx[,"percent_within"] = NA
  for (i in 1:nrow(conf_mtx)){
    for (j in 1:length(lvl)){
      if (conf_mtx[i,"Source_Groups"] == lvl[j]){
        sum_relevant_rows <- conf_mtx %>% dplyr::filter(Source_Groups == lvl[j])
        sum_relevant_rows <- sum(sum_relevant_rows$Freq)
        conf_mtx[i,"percent_within"] = as.numeric(conf_mtx[i,"Freq"])/sum_relevant_rows
      }
      else {return}
    }
  }
  return(conf_mtx)
}
```
The next function takes the output of the previous function to calculate the within and outside group collaboration for levels of a particular attribute.
```{r}
get_in_out_tbl <- function(conf_mtx){
  sum_tbl <- conf_mtx %>% dplyr::group_by(Source_Groups) %>% 
    dplyr::summarise(dist = sum(Freq)) %>%
    select(Source_Groups,dist) %>% 
    filter(is.na(dist)==FALSE) %>% 
    arrange(desc(dist))
  in_out_pct <- conf_mtx %>% 
    dplyr::mutate(match = ifelse(Source_Groups == Target_Groups,"within group","outside group"), 
                  percent_within = ifelse(is.na(percent_within)==TRUE, 0, percent_within)) %>% 
    dplyr::group_by(Source_Groups, match) %>% 
    dplyr::summarise(in_out_pct = sum(percent_within))
  return(in_out_pct)
}
```

The following functions use the utility functions listed above and get network statistics by year and overall.
```{r}
analyze_graph <- function(g, nodes, edges, attr) {
  #attr: Group, Activity, Discipline
  stats = list()
  print(attr)
  # 1.assortativity
  assortativity = get_assortativity(g, attr)
  stats$assortativity = assortativity
# 2. Average degree, transtivity, and degee distributions
  g = get_degree(g, attr)
  g = get_transitivity(g)
  var = vertex_attr(g, attr)
  lvls =  unique(var)
  lvl_len = length(lvls)
  dgs = list()
  trs = list()
  strs = list()
  dg_dist = list()
  for (i in 1:lvl_len) {
    lvl = lvls[i]
    lvl_nodes = V(g)[var == lvl]
    dgs[[lvl]] = mean(lvl_nodes$degree,  na.rm = TRUE)
    trs[[lvl]] = mean(lvl_nodes$cc,  na.rm = TRUE)
    strs[[lvl]] = mean(lvl_nodes$strength,  na.rm = TRUE)
    dg = degree.distribution(g, v=lvl_nodes)
    dg_dist[[lvl]] = dg
  }
  dgs[['all_nodes']] =   mean(V(g)$degree, na.rm = TRUE)
  strs[['all_nodes']] =   mean(V(g)$strength, na.rm = TRUE)
  all_dg = degree.distribution(g)
  dg_dist[['all_nodes']] = all_dg
  
  stats$degree = dgs
  stats$strength = strs
  stats$transitivity = trs
  stats$degree_dist =  dg_dist
  
  # 3. confusion matrix  dyad level
  prop_table = get_group_confusion(nodes, edges, attr)
  stats$prop_table = prop_table
  
  # 3a. within group vs outside group %
  in_out_table = get_in_out_tbl(get_confusion_within_group(prop_table))
  stats$in_out_table = in_out_table
  
  ## calcuate graph level statistics
  # the ratio of the number of edges and the number of possible edges
  stats$density = edge_density(g, loops=FALSE)
  
  
  #count group membership in complete triad graph
  print(paste(rep('#', 30),collapse = ''))
  n = 3 
  m = get_cliques_membership(g, n, attr)
  
  triad_counts = list()
  for (i in 1:lvl_len) {
    lvl = lvls[i]
    lvl_nodes = V(g)[var == lvl]
    triad_count = sum(m[, lvl] == 3)
    triad_counts[[lvl]] = triad_count
  }
  stats$triads_counts = triad_counts
  return(stats)
  #group blocks
  #clustering analysis
  #get_blockmodel()
}

get_stats <- function(g, attr) {
  all_years_stats = analyze_graph(g, nodes, edges,attr)
  # looping over years
  yr_range = 2002:2016
  stats_by_year = list()
  for (yr in yr_range) {
    yr_edges = edges[edges$PUB_YEAR<=yr,]
    yr_g = build_graph(nodes, yr_edges)
    stat =  analyze_graph(yr_g, nodes, yr_edges, attr)
    print(stat)
    stats_by_year[[as.character(yr)]]  = stat
  }
  stats = list()
  stats[['all_years_stats']] = all_years_stats
  stats[['stats_by_year']] = stats_by_year
  return(stats)
}
```

**Plotting Functions**

This function plots the Degree Distribution.
```{r}
plot_deg_dist1 <- function(stats) {
  par(mai=c(0.5, 0.5, 0.5, 0.5))
  
  # layout(cbind(1,2), widths=c(6,1))  # put legend on bottom 1/8th of the chart
  all_years_stats = stats$all_years_stats
  dists = all_years_stats$degree_dist
  n = length(dists)
  palette <- distinctColorPalette(n)
  #palette<- c("blue","green4")
  
  dists = all_years_stats$degree_dist
  all_node_dist = dists[['all_nodes']]
  all_dgs = 1:length(all_node_dist)
  all_dgs = all_dgs[all_node_dist != 0]
  all_node_dist = all_node_dist[all_node_dist != 0]
  plot( x=all_dgs[all_dgs < 20], y=all_node_dist[all_dgs < 20], pch=19, cex=0.5, col="black", 
        xlab="Degree", ylab="Frequency", ylim=c(0, 0.2), type="o",lty=1,lwd = 2)
  lvls = names(dists)
  for (i in 1:length(lvls)) {
    lvl = lvls[[i]]
    if ( lvl != 'all_nodes') {
      lvl_dist = dists[[lvl]]
      lvl_dg= 1:length(lvl_dist)
      lvl_dg = lvl_dg[lvl_dist != 0]
      lvl_dist = lvl_dist[lvl_dist != 0]
      lines( x=lvl_dg[lvl_dg < 20], y=lvl_dist[lvl_dg < 20], pch=19, cex=0.5, col=palette[[i]], 
             xlab="Degree", ylab="Frequency", type="o", lty=1, lwd = 2)
    }
  }
  legend(15, 0.17, c('all_nodes', lvls[1:length(lvls)-1]), col = c('black',palette[1:length(lvls)-1]),
         text.col = c('black',palette[1:length(lvls)-1]), lty = 1,
         merge = TRUE, xpd=T, cex=1)
  #dev.off()
}
```
This function plots the confusion matrix as a heat map.
```{r}
plot_block_heatmap <- function(conf) {
  conf.l = melt(conf)
  ggplot(conf.l, aes(Source_Groups, Target_Groups)) + geom_tile(aes(fill = value),colour = "white")  +  
  scale_fill_gradient(low = "white", high = "steelblue") +
 theme(axis.text.x = element_text(angle = 90, hjust = 1))
}
```
This function plots the within and outside group percentages by level of attribute.
```{r}
plot_in_out <- function(stats, attr_name){
  plot.data <- stats$all_years_stats$in_out_table %>% 
    arrange(Source_Groups, desc(match))%>%
    filter(Source_Groups != 'NULL.'& Source_Groups != 'PHYS'&
             Source_Groups != 'COMP' & Source_Groups != 'ENGI') %>%
    filter(Source_Groups != 'DP1'& Source_Groups != 'P42'& Source_Groups != 'P51'&
             Source_Groups != 'P60'& Source_Groups != 'R21'& Source_Groups != 'R33'&
             Source_Groups != 'R56'& substr(Source_Groups,1,2) != 'RC'&
             Source_Groups != 'RL1'& Source_Groups != 'U01'& Source_Groups != 'U41'&
             Source_Groups != 'UH2'& Source_Groups != 'UL1'& Source_Groups != 'UM1')
  plot.data$Source_Groups <- as.factor(plot.data$Source_Groups)
  ggplot(data=plot.data, aes(x=Source_Groups, y=in_out_pct, fill=match)) +
    geom_bar(stat='identity') + coord_flip() +
    scale_fill_manual(values=c("slategray2", "navyblue")) +
    xlab(attr_name) + ylab("Percentage of Group") + 
    ggtitle("Percentage of Collaboration Within and Outside of Group") 
}
```
Function to print statistics.
```{r}
print_stat <- function(all_years_stats) {
  
  print(paste(c(rep('#', 15), 'assortativity', rep('#', 15)),collapse = ''))
  print(paste0('assortativity: ', as.character(all_years_stats$assortativity)))
  cat('\n')
  cat('\n')
  
  #print degree
  print(paste(c(rep('#', 15), 'Degree', rep('#', 15)),collapse = ''))
  dgs = all_years_stats[['degree']]
  dns = names(dgs)
  for (d in dns) {
    print(paste0('Average ', d,  ' Degree: ', sprintf("%.6f",dgs[[d]] )))
  }
  cat('\n')
  cat('\n')
  
  print(paste(c(rep('#', 15), 'Confusion Table', rep('#', 15)),collapse = ''))
  print(all_years_stats$prop_table)
  cat('\n')
  cat('\n')
  
  #print Transitivity
  print(paste(c(rep('#', 15), 'Transitivity', rep('#', 15)),collapse = ''))
  print('The below statistics ignore nodes without edges')
  trs = all_years_stats[['transitivity']]
  tns = names(trs)
  for (t in tns) {
    print(paste0('Average ', t,  ' Transitivity: ', sprintf("%.6f",trs[[t]] )))
  }
  cat('\n')
  cat('\n')
  
  #print triad count
  print(paste(c(rep('#', 15), 'Complete Triads', rep('#', 15)),collapse = ''))
  t_c = all_years_stats[['triads_counts']]
  tns = names(t_c)
  for (t in tns) {
    print(paste0('The number of  ', t,  ' Complete Triads: ', sprintf("%.6f",t_c[[t]] )))
  }
  cat('\n')
  cat('\n')
  
}
```



**Analysis**

Load edge and node files.  Only include complete nodes and build graph.
```{r}
node_file = 'C:/Users/Marissa/OneDrive/Group Folder/2017-03-31 Network Analysis/Wei/data/node classification/nodes_added_grouped_attributes.csv'
edge_file = 'C:/Users/Marissa/OneDrive/Group Folder/2017-03-31 Network Analysis/Wei/data/node classification/study_comp_edges_disc.csv'

nodes = read.csv(node_file, header = T)
nodes = nodes[complete.cases(nodes$Id),]
edges = read.csv(edge_file, header = T)

g <- build_graph(nodes, edges)
```

Question 1
```{r, results='hide'}
q1_stats = get_stats(g, attr='Group')
```

```{r, echo=FALSE}
print('Q1: Does NIGMS researchers collaborate with each other more ofthen than with other groups?')
q1_all_years_stats = q1_stats[['all_years_stats']] 
print_stat(q1_all_years_stats)
#plot_deg_dist1(q1_all_years_stats)
plot_block_heatmap(q1_all_years_stats$prop_table)
plot_in_out(q1_stats,"Comparison vs Study Group")
```

Question 2
```{r, results='hide'}
q2_stats = get_stats(g, attr='ACTIVITY')
```

```{r, echo=FALSE}
print('Q2 Does the type of grant awarded influence collaboration behavior?')
q2_all_years_stats = q2_stats[['all_years_stats']] 
print_stat(q2_all_years_stats)
plot_block_heatmap(q2_all_years_stats$prop_table)
#plot_deg_dist1(q2_all_years_stats)
plot_in_out(q2_stats,"Grant Type")
```

Question 3
```{r, results='hide'}
q3_stats = get_stats(g, attr='Act_per_proj_quant')
```

```{r, echo=FALSE}
print('Q3 Does variety in funding sources influence collaboration behavior?')
q3_all_years_stats = q3_stats[['all_years_stats']] 
print_stat(q3_all_years_stats)
plot_block_heatmap(q3_all_years_stats$prop_table)
#plot_deg_dist1(q3_all_years_stats)
plot_in_out(q3_stats,"Activities per Project Bucket")
```

Question 4
```{r, results='hide'}
q4_stats = get_stats(g, attr='discipline_classification')
```

```{r, echo=FALSE}
print('Q4 Does the scientific discipline influence collaboration behavior?')
q4_all_years_stats = q4_stats[['all_years_stats']] 
print_stat(q4_all_years_stats)
plot_block_heatmap(q4_all_years_stats$prop_table)
#plot_deg_dist1(q4_all_years_stats)
plot_in_out(q4_stats,"Discipline")
```